/*
_____ _ _ _ _ _
| ___(_) | |_ ___ _ __ _ __ | |_ _ __ _(_)_ __
| |_ | | | __/ _ \ '__| | '_ \| | | | |/ _` | | '_ \
| _| | | | || __/ | | |_) | | |_| | (_| | | | | |
|_| |_|_|\__\___|_| | .__/|_|\__,_|\__, |_|_| |_|
|_| |___/
# A Template for Pose_estimationPlugin, a Filter Plugin
# Generated by the command: plugin -t filter -d pose_estimation_plugin
pose_estimation # Hostname: MacBook-Air-di-Alberto-6.local # Current working
directory:
/Users/alberto/MECHATRONIC_ENGINEERING/ROBOTIC_PERCEPTION/PROJECT/PLUGIN #
Creation date: 2025-11-28T17:25:29.889+0100 # NOTICE: MADS Version 1.4.0
*/
// Mandatory included headers

#include <Eigen/Dense> // N.B.: brew install eigen, then add in .vscode the header for this lib
#include <cmath>
#include <filter.hpp>
#include <iostream>
#include <nlohmann/json.hpp>
#include <pugg/Kernel.h>

// Define the name of the plugin
#ifndef PLUGIN_NAME
#define PLUGIN_NAME "pose_estimation"
#endif

#define PRINT_INPUT 0
#define PRINT_OUTPUT 0
#define REAL_TIME 0 // 1 for real-time operation, 0 for offline processing
#define USE_IMU 0 // 1 if IMU data is available and should be used in the EKF update, 0 otherwise
#define USE_REALSENSE 1 // 1 if Realsense data is available and should be used in the EKF update, 0 otherwise
#define USE_COMPASS 1 // 1 if Compass data is available and should be used to correct the heading, 0 otherwise

// Load the namespaces
using namespace std;
using json = nlohmann::json;

// Static variables to keep track of sensors values and time
static bool first = false;
static bool second = false;
static int last_enc_L = 0;
static int last_enc_R = 0;      // TODO: check!
bool first_imu = true;



// _________________________________________ CLASSES ______________________________________________

// Define a class to store ENCODER data
class EncoderData {
public:
  int left_encoder;
  int right_encoder;
  double timecode;
  EncoderData() : left_encoder(0), right_encoder(0), timecode(0.0) {}
};

// Define a class to store HTC data
class HTCData {
public:
  float x;
  float y;
  float z;
  double timecode;
  HTCData() : x(0.0), y(0.0), z(0.0), timecode(0.0) {}
};

// Define a class to store REALSENSE data
class RealsenseData {
public:
  float x;
  float y;
  float z;
  double theta;
  double timecode;
  RealsenseData() : x(0.0), y(0.0), z(0.0), theta(0.0), timecode(0.0) {}
};

// Define a class to store IMU data
class IMUData {
public:
  float acc_x;
  float acc_y;
  float acc_z;
  float gyro_x;
  float gyro_y;
  float gyro_z;
  double fusion_roll;
  double fusion_pitch;
  double fusion_yaw;
  double compass_x;
  double compass_y;
  double compass_z;
  double timecode;
  IMUData()
      : acc_x(0.0), acc_y(0.0), acc_z(0.0), gyro_x(0.0), gyro_y(0.0),
        gyro_z(0.0), fusion_roll(0.0), fusion_pitch(0.0), fusion_yaw(0.0),
        compass_x(0.0), compass_y(0.0), compass_z(0.0), timecode(0.0) {}
};

// Define a class to store POSE data
class PoseData {
public:
  double x;
  double y;
  double z;
  double theta;
  double timecode;
  PoseData() : x(0.0), y(0.0), z(0.0), theta(0.0), timecode(0.0) {}
};

class ExtendedKalmanFilter {
public:
  ExtendedKalmanFilter(double R_L, double R_R, double wheel_base,
                       int ticks_per_rev)
      : R_L_(R_L), R_R_(R_R), b_(wheel_base), n0_(ticks_per_rev) {
    // Inizializzazione matrici dimensione fissa
    Q_.setZero();
    R_rs_.setZero();
    R_imu_.setZero();
    // Valori di default (verranno sovrascritti da set_tuning)
    init_matrices_default();

    initialized_ = false;
  }

  void init(double x0, double y0, double theta0, double t0) {
    x_(0) = x0;
    x_(1) = y0;
    x_(2) = theta0;
    t_last_ = t0;
    // --- FIX IMPORTANTE: Reset della Covarianza ---
    P_.setIdentity();
    P_ *= 0.1; // Partiamo con incertezza bassa ma non nulla
    initialized_ = true;
  }

  // Tuning method to update Q and R matrices
  void set_tuning(double q_pos, double q_yaw, double r_imu, double r_rs_pos,
                  double r_rs_yaw) {
    Q_.setZero();
    Q_(0, 0) = q_pos;
    Q_(1, 1) = q_pos;
    Q_(2, 2) = q_yaw;

    R_imu_.setZero();
    R_imu_(0, 0) = r_imu;

    R_rs_.setZero();
    R_rs_(0, 0) = r_rs_pos;
    R_rs_(1, 1) = r_rs_pos;
    R_rs_(2, 2) = r_rs_yaw;
  }

  void predict(double t_now, int nL, int nR, double dt) {
    if (!initialized_)
      return;

    /* 
    double dt = t_now - t_last_;
    if (dt <= 0.00001 || dt > 1.0) { // Check dt validi
      t_last_ = t_now;
      return;
    }
    */

    // 1. Cinematica
    double d_left = (2.0 * M_PI * R_L_ * nL) / n0_;
    double d_right = (2.0 * M_PI * R_R_ * nR) / n0_;
    double ds = (d_right + d_left) / 2.0;
    double dtheta = (d_right - d_left) / b_;
    // Se ds e dtheta sono 0 (robot fermo), P cresce comunque per via di Q
    // (drift) Ma va bene così.

    double theta = x_(2);
    double avg_theta = theta + dtheta / 2.0;
    // 2. State Update
    x_(0) = x_(0) + ds * std::cos(avg_theta);
    x_(1) = x_(1) + ds * std::sin(avg_theta);
    x_(2) = x_(2) + dtheta;
    x_(2) = std::atan2(std::sin(x_(2)), std::cos(x_(2))); // Normalizza

    // 3. Covariance Update
    // Jacobian F rispetto a [x, y, theta]
    Eigen::Matrix3d F = Eigen::Matrix3d::Identity();
    F(0, 2) = -ds * std::sin(avg_theta);
    F(1, 2) = ds * std::cos(avg_theta);

    P_ = F * P_ * F.transpose() + Q_;

    t_last_ = t_now;
  }

  void update_realsense(double rs_x, double rs_y, double rs_theta) {
    if (!initialized_)
      return;

    Eigen::Vector3d z;
    z << rs_x, rs_y, rs_theta;

    Eigen::Matrix3d H = Eigen::Matrix3d::Identity();
    Eigen::Vector3d y = z - x_;
    y(2) =
        std::atan2(std::sin(y(2)), std::cos(y(2))); // Shortest angular distance

    Eigen::Matrix3d S = H * P_ * H.transpose() + R_rs_;
    Eigen::Matrix3d K = P_ * H.transpose() * S.inverse();

    // --- DEBUG PRINT: SCOMMENTA PER CAPIRE CHI COMANDA ---
    // Se K(0,0) è > 0.5, l'EKF si fida più della Realsense
    // Se K(0,0) è < 0.1, l'EKF si fida più degli Encoder
    std::cout << "EKF Gain K_pos: " << K(0, 0) << " | P_pos: " << P_(0, 0)
              << std::endl;

    x_ = x_ + K * y;
    P_ = (Eigen::Matrix3d::Identity() - K * H) * P_;
    x_(2) = std::atan2(std::sin(x_(2)), std::cos(x_(2)));
  }

  void update_imu(double imu_gyro_z, double dt_imu) {
    if (!initialized_)
      return;

    // --- FIX LOGICA IMU ---
    // Niente offset strani. Assumiamo che imu_yaw sia nello stesso frame
    // ENU/NED Se l'IMU è ruotata, gestiscilo nel "load_data", non qui dentro.
    double z = imu_gyro_z * dt_imu;     // Integrazione angolare
    Eigen::RowVector3d H;
    H << 0, 0, 1; // Misuriamo solo Theta

    // Calcolo residuo angolare corretto
    double y_res = z - x_(2);
    y_res = std::atan2(std::sin(y_res), std::cos(y_res)); // Normalizza tra -PI e PI

    double S = (H * P_ * H.transpose())(0, 0) + R_imu_(0, 0);
    // K è un vettore 3x1 (guadagno su x, y, theta dato l'errore di angolo)
    Eigen::Vector3d K = P_ * H.transpose() / S;

    x_ = x_ + K * y_res;
    P_ = (Eigen::Matrix3d::Identity() - K * H) * P_;
    x_(2) = std::atan2(std::sin(x_(2)), std::cos(x_(2)));
  }

  double update_compass(double mx, double my, double mz) {
    // --- 1. CALIBRAZIONE (Valori ottenuti dallo script MATLAB) ---
    // Inserisci qui i risultati del calcolo Hard-Iron
    const double offset_x = -4.9091; // Esempio: valore medio x
    const double offset_y = -4.9091;  // Esempio: valore medio y
    const double scale_x  = 0.5862;    // Opzionale: correzione ellitticità
    const double scale_y  = 3.3986;

    double mx_corr = (mx - offset_x) * scale_x;
    double my_corr = (my - offset_y) * scale_y;

    // --- 2. CALCOLO HEADING (Angolo Magnetico) ---
    // Usiamo -my perché, come da tuo datasheet, l'asse Z/rotazione è invertito
    double compass_yaw = std::atan2(-my_corr, mx_corr);

    // --- 3. ALLINEAMENTO INIZIALE (Relativo allo "0" del Walker) ---
    // La bussola punta al Nord, ma il tuo robot all'avvio punta verso lo "0" degli encoder.
    if (!compass_initialized) {
        compass_offset = compass_yaw; 
        compass_initialized = true;
        std::cout << "Compass aligned to robot zero. Offset: " << compass_offset << std::endl;
    }

    // Calcolo l'angolo relativo alla posizione di partenza
    double yaw_measured = compass_yaw - compass_offset;

    // Normalizzazione nell'intervallo [-PI, PI]
    yaw_measured = std::atan2(std::sin(yaw_measured), std::cos(yaw_measured));

    return yaw_measured;
  }

  // Funzione generica per aggiornare SOLO la posizione X e Y (senza toccare Theta)
void update_position(double pos_x, double pos_y, double R_variance) {
    if (!initialized_) return;

    // 1. Vettore di misura z
    Eigen::Vector2d z;
    z << pos_x, pos_y;

    // 2. Matrice di osservazione H (Estrae solo x e y dallo stato [x,y,theta])
    Eigen::Matrix<double, 2, 3> H;
    H << 1, 0, 0,
         0, 1, 0;

    // 3. Matrice di covarianza del rumore di misura R
    // Usiamo una varianza alta perché l'accelerometro integrato "deriva" molto
    Eigen::Matrix2d R;
    R << R_variance, 0,
         0, R_variance;

    // 4. Calcolo Innovazione (y) e Gain (K)
    Eigen::Vector2d y = z - H * x_; // Residuo
    
    // S = H*P*H' + R
    Eigen::Matrix2d S = H * P_ * H.transpose() + R;
    
    // K = P*H'*S^-1
    Eigen::Matrix<double, 3, 2> K = P_ * H.transpose() * S.inverse();

    // 5. Aggiornamento Stato
    x_ = x_ + K * y;

    // 6. Aggiornamento Covarianza P
    P_ = (Eigen::Matrix3d::Identity() - K * H) * P_;
    
    // Normalizzazione Theta (anche se non toccato direttamente, per sicurezza numerica)
    x_(2) = std::atan2(std::sin(x_(2)), std::cos(x_(2)));
}

// Funzione principale che implementa la TUA logica di elaborazione IMU
void process_accel_data(double ax, double ay, double az, 
                        double gyro_z, double fusion_roll, double fusion_pitch, 
                        double dt, bool is_robot_stopped) {
    
    if (!initialized_ || dt <= 0.0) return;

    // --- 0. ZUPT (Zero Velocity Update) ---
    // SE IL ROBOT È FERMO (dagli encoder), AZZERIAMO LA VELOCITÀ INTEGRATA
    // Questo è fondamentale per evitare che la posizione parta per la tangente.
    if (is_robot_stopped) {
        vel_imu_x = 0.0;
        vel_imu_y = 0.0;
        // Non facciamo update o integrazione se siamo fermi
        return;
    }

    // --- 1. ROTAZIONE FRAME IMU -> FRAME ROVER ---
    // Dal tuo snippet: x->y, y->x, z->z (sinistrorso?)
    Eigen::Matrix3d R_imu_to_rover;
    R_imu_to_rover << 0, 1, 0,
                      1, 0, 0,
                      0, 0, 1;

    Eigen::Vector3d a_raw_g(ax, ay, az);
    // Convertiamo in m/s^2 e ruotiamo
    Eigen::Vector3d a_PM = R_imu_to_rover * (a_raw_g * 9.81);

    // --- 2. ACCELERAZIONE ANGOLARE (w_dot) ---
    double w_dot_z = 0.0;
    if (dt > 1e-6) {
        w_dot_z = (gyro_z - prev_gyro_z_) / dt;
    }
    prev_gyro_z_ = gyro_z;

    Eigen::Vector3d w(0.0, 0.0, gyro_z);
    Eigen::Vector3d w_dot(0.0, 0.0, w_dot_z);
    
    // --- 3. LEVER ARM COMPENSATION (IMU position relative to rover RF) ---
    // IMU spostata di 70cm in X e -20cm in Y
    Eigen::Vector3d r_MP(0.70, -0.20, 0.0);

    // a_rover = a_imu - w_dot x r - w x (w x r)
    Eigen::Vector3d a_MO = a_PM - w_dot.cross(r_MP) - w.cross(w.cross(r_MP));

    // --- 4. RIMOZIONE GRAVITÀ (Usando Roll e Pitch Fusionati) ---
    Eigen::Vector3d g_rover;
    g_rover.x() = -9.81 * std::sin(fusion_pitch);
    g_rover.y() =  9.81 * std::sin(fusion_roll) * std::cos(fusion_pitch);
    g_rover.z() =  9.81 * std::cos(fusion_roll) * std::cos(fusion_pitch);

    a_MO -= g_rover; // Ora a_MO è l'accelerazione lineare pura nel Rover Frame

    // --- 5. ROTAZIONE NEL WORLD FRAME (Usando lo Yaw attuale dell'EKF) ---
    // Usiamo lo stato x_(2) dell'EKF perché è la stima migliore dell'orientamento
    double yaw = x_(2); 
    double c = std::cos(yaw);
    double s = std::sin(yaw);

    // Rotazione 2D (assumiamo piano 2D per il world frame)
    double ax_world = c * a_MO.x() - s * a_MO.y();
    double ay_world = s * a_MO.x() + c * a_MO.y();

    // --- 6. INTEGRAZIONE (Accel -> Vel -> Pos) ---
    vel_imu_x += ax_world * dt;
    vel_imu_y += ay_world * dt;

    pos_imu_accum_x += vel_imu_x * dt;
    pos_imu_accum_y += vel_imu_y * dt;

    // --- 7. UPDATE EKF ---
    // Passiamo la posizione calcolata all'EKF.
    // IMPORTANTE: R deve essere ALTO (es. 5.0 o 10.0)
    update_position(pos_imu_accum_x, pos_imu_accum_y, 5.0);
}

// Setter per inizializzare la posizione accumulata allo start
void reset_imu_integration(double x0, double y0) {
    pos_imu_accum_x = x0;
    pos_imu_accum_y = y0;
    vel_imu_x = 0.0;
    vel_imu_y = 0.0;
}

  Eigen::Vector3d getState() const { return x_; }

private:
  void init_matrices_default() {
    P_.setIdentity();
    // Default Tuning (sicurezza)
    Q_.setIdentity();
    Q_ *= 0.01;
    R_rs_.setIdentity();
    R_rs_ *= 0.1;
    R_imu_.setIdentity();
    R_imu_ *= 0.1;
  }

  Eigen::Vector3d x_;
  Eigen::Matrix3d P_, Q_, R_rs_, R_imu_;

  double R_L_, R_R_, b_;
  int n0_;
  bool initialized_;
  double t_last_;

  bool compass_initialized = false;
  double compass_offset = 0.0;
  double prev_gyro_z_ = 0.0;
  // Variabili per l'integrazione
  double vel_imu_x = 0.0;
  double vel_imu_y = 0.0;
  double pos_imu_accum_x = 0.0;
  double pos_imu_accum_y = 0.0;
};

// _______________________________________________________________________________________________

// Plugin class. This shall be the only part that needs to be modified,
// implementing the actual functionality
class Pose_estimationPlugin : public Filter<json, json> {

public:
  string kind() override { return PLUGIN_NAME; }

  return_type load_data(json const &input, string topic = "") override {

    // Store data from encoders
    if (topic == "encoders") {
      printf("Storing encoder data...\n");
      const auto &root = REAL_TIME ? input : input["message"];
      if (root.contains("encoders")) {
        const auto &E = root["encoders"];
        if (E.contains("left") && E["left"].is_number()) {
          encoder_data.left_encoder = E["left"].get<int>();
          if (!second) {
            first = true;
          }
        }
        if (E.contains("right") && E["right"].is_number()) {
          encoder_data.right_encoder = E["right"].get<int>();
        }
      }
      if (root.contains("timecode") && root["timecode"].is_number()) {
        encoder_data.timecode = root["timecode"].get<double>();
      }
    }

    // Store data from HTC (position is a vector with x,y,z)
    if (topic == "htc") {
      printf("Storing HTC data...\n");
      const auto &root = REAL_TIME ? input : input["message"];
      if (root.contains("pose") && root["pose"].contains("position")) {
        const auto &P = root["pose"]["position"];
        if (P.is_array() && P.size() >= 3) {

          if (P[0].is_number()) {
            htc_data.x = P[0].get<float>();
          }
          if (P[1].is_number()) {
            htc_data.y = P[1].get<float>();
          }
          if (P[2].is_number()) {
            htc_data.z = P[2].get<float>();
          }
        }
      }
      if (root.contains("timecode") && root["timecode"].is_number()) {
        htc_data.timecode = root["timecode"].get<double>();
      }
    }

    // Store data from Realsense
    if (topic == "H_initial_walker_aruco") {
      const auto &root = REAL_TIME ? input : input["message"];
      if (root.contains("pose") && root["pose"].contains("position")) {
        const auto &P = root["pose"]["position"];
        if (P.is_array() && P.size() >= 3) {
          if (P[0].is_number())
            realsense_data.x = P[0].get<float>(); //+ 0.2245;
          if (P[1].is_number())
            realsense_data.y = P[1].get<float>(); //- 0.1744;
          if (P[2].is_number())
            realsense_data.z = P[2].get<float>();
        }
      }
      if (root.contains("pose") && root["pose"].contains("attitude")) {
        const auto &A = root["pose"]["attitude"];
        if (A.is_array() && A.size() >= 3) {
          if (A[2].is_number()) {
            realsense_data.theta = A[2].get<float>();
          }
        }
      }
      if (root.contains("timecode") && root["timecode"].is_number()) {
        realsense_data.timecode = root["timecode"].get<double>();
      }
    }

    // Store data from IMU
    if (topic == "imu") {
      const auto &root = REAL_TIME ? input : input["message"];
      if (root.contains("accel")) {
        const auto &A = root["accel"];
        if (A.is_array() && A.size() >= 3) {
          if (A[0].is_number())
            imu_data.acc_x = A[1].get<float>(); // - a_x_off_imu; // g

          if (A[1].is_number())
            imu_data.acc_y = A[0].get<float>(); // - a_y_off_imu;

          if (A[2].is_number())
            imu_data.acc_z = A[2].get<float>();
        }
      }
      if (root.contains("gyro")) {
        const auto &G = root["gyro"];
        if (G.is_array() && G.size() >= 3) {
          if (G[0].is_number())
            imu_data.gyro_x = G[0].get<float>(); // rad/s
          if (G[1].is_number())
            imu_data.gyro_y = G[1].get<float>();
          if (G[2].is_number())
            imu_data.gyro_z = - G[2].get<float>(); // - w_z_off_imu; // Z axis inverted
        }
      }
      if (root.contains("fusionPose")) {
        const auto &F = root["fusionPose"];
        if (F.is_array() && F.size() >= 3) {
          if (F[0].is_number())
            imu_data.fusion_roll = F[0].get<double>(); // rad
          if (F[1].is_number())
            imu_data.fusion_pitch = F[1].get<double>();
          if (F[2].is_number())
            imu_data.fusion_yaw = F[2].get<double>();
        }
      }
      if (root.contains("compass")) {
        const auto &C = root["compass"];
        if (C.is_array() && C.size() >= 3) {
          if (C[0].is_number())
            imu_data.compass_x = C[0].get<double>();
          if (C[1].is_number())
            imu_data.compass_y = C[1].get<double>();
          if (C[2].is_number())
            imu_data.compass_z = C[2].get<double>();
        }
      }
      if (root.contains("timecode") && root["timecode"].is_number()) {
        imu_data.timecode = root["timecode"].get<double>();
      }
    }

    if (PRINT_INPUT) {
      // cout << "\n\n___________ Input data: ____________\n\n" << input.dump(2)
      // << endl;
      cout << "\n\n___________ Stored data: ____________\n\n";
      cout << "Encoders: Left = " << encoder_data.left_encoder
           << ", Right = " << encoder_data.right_encoder << endl;
      cout << "HTC Position: x = " << htc_data.x << ", y = " << htc_data.y
           << ", z = " << htc_data.z << endl;
      cout << "Realsense Position: x = " << realsense_data.x
           << ", y = " << realsense_data.y << ", z = " << realsense_data.z
           << endl;
      cout << "IMU Accel: x = " << imu_data.acc_x << ", y = " << imu_data.acc_y
           << ", z = " << imu_data.acc_z << endl;
      cout << "Timecode: " << encoder_data.timecode << endl;
    }

    return return_type::success;
  }

  return_type process(json &out) override {
    // 0. COMPUTE DELTA TICKS
    if (first) {
      last_enc_L = encoder_data.left_encoder;
      last_enc_R = encoder_data.right_encoder;
      last_time_enc = encoder_data.timecode;
      last_time_rs = realsense_data.timecode;
      last_time_imu = imu_data.timecode;
      second = true;
      first = false;
      ekf_ptr->init(0.0, 0.0, 0.0, encoder_data.timecode);      // Inizializza l'EKF con la prima posizione nota (es. 0 o da Realsense se disponibile)
      cout << "EKF Initialized" << endl;
      return return_type::success;          // Salta il primo ciclo per sicurezza
    }
    float dt_enc = encoder_data.timecode - last_time_enc;
    last_time_enc = encoder_data.timecode;
    double dt_rs = realsense_data.timecode - last_time_rs;
    last_time_rs = realsense_data.timecode;
    double dt_imu = imu_data.timecode - last_time_imu;
    last_time_imu = imu_data.timecode;



    // 1. PREDICTION WITH ENCODER DATA
    int n_Lk = encoder_data.left_encoder - last_enc_L;
    int n_Rk = encoder_data.right_encoder - last_enc_R;
    last_enc_L = encoder_data.left_encoder;
    last_enc_R = encoder_data.right_encoder;
    ekf_ptr->predict(encoder_data.timecode, n_Lk, n_Rk, dt_enc);



    // 2. UPDATE CON REALSENSE E IMU DATA
    if (USE_REALSENSE) {
      ekf_ptr->update_realsense(realsense_data.x, realsense_data.y, realsense_data.theta);  // Corregge (X, Y, Theta)
    }

    if (USE_IMU) {
      ekf_ptr->update_imu(imu_data.gyro_z, dt_imu);   // Corregge solo Theta
    }
    
    double yaw_measured = 0.0;
    if(USE_COMPASS){
      yaw_measured = ekf_ptr->update_compass(imu_data.compass_x, imu_data.compass_y, imu_data.compass_z);
      ekf_ptr->update_imu(yaw_measured, dt_imu); // Corregge solo Theta
    }



    // 3. JSON OUTPUT PREPARATION
    double ds_enc = M_PI * (n_Rk * R_R + n_Lk * R_L) / n0;
    double dtheta_enc = 2.0 * M_PI * (n_Rk * R_R - n_Lk * R_L) / (n0 * b);
    double avg_th = pose_data_enc.theta + dtheta_enc / 2.0;   // Integrazione della posa (usando l'angolo medio per precisione)
    pose_data_enc.x += ds_enc * std::cos(avg_th);
    pose_data_enc.y += ds_enc * std::sin(avg_th);
    pose_data_enc.theta += dtheta_enc;
    pose_data_enc.theta = std::atan2(std::sin(pose_data_enc.theta), std::cos(pose_data_enc.theta));
    pose_data_enc.timecode = encoder_data.timecode;

    pose_data_realsense.x = realsense_data.x;
    pose_data_realsense.y = realsense_data.y;
    pose_data_realsense.z = 0.0;                              // assuming z=0 for realsense
    pose_data_realsense.timecode = encoder_data.timecode;     // realsense_data.timecode;     // TODO:check

    if (!first_imu) {
      // 1. Ruota l'accelerazione lineare dal frame Rover al frame World usando
      // lo Yaw
      float yaw_imu = yaw_measured; // TODO: imu_data.fusion_yaw;
      // Usiamo l'accelerazione lungo l'asse X del rover (avanti)
      // Nota: imu_data.acc_x è già depurata dal bias nel tuo load_data
      double acc_x_world = (imu_data.acc_x * 9.81) * std::cos(yaw_imu);
      double acc_y_world = (imu_data.acc_x * 9.81) * std::sin(yaw_imu);

      // 2. Prima integrazione: Accelerazione -> Velocità
      x_dot_IMU += acc_x_world * dt_enc;
      y_dot_IMU += acc_y_world * dt_enc;

      // 3. Seconda integrazione: Velocità -> Posizione
      pose_data_imu.x += x_dot_IMU * dt_enc;
      pose_data_imu.y += y_dot_IMU * dt_enc;
      pose_data_imu.theta = yaw_imu;
      pose_data_imu.timecode = imu_data.timecode;
    }
    first_imu = false;

    Eigen::Vector3d x_est = ekf_ptr->getState();
    pose_data_ekf.x = x_est(0);
    pose_data_ekf.y = x_est(1);
    pose_data_ekf.theta = x_est(2);
    pose_data_ekf.z = 0.0;

    pose_data_htc.x = htc_data.x;
    pose_data_htc.y = htc_data.y;
    pose_data_htc.z = 0.0; // assuming z=0 for HTC
    pose_data_htc.timecode = htc_data.timecode;


    // 4. CALCOLO MSE (ground truth HTC vs EKF)
    compute_mse(pose_data_htc.x, pose_data_htc.y, pose_data_ekf.x, pose_data_ekf.y);


    // 5. OUTPUT JSON
    out.clear();
    out["encoders"] = {{"left", encoder_data.left_encoder}, {"right", encoder_data.right_encoder}};
    out["htc"] = {htc_data.x, htc_data.y, htc_data.z};
    out["realsense"] = {realsense_data.x, realsense_data.y, realsense_data.z};
    out["imu"] = {imu_data.acc_x, imu_data.acc_y, imu_data.acc_z};
    out["position_enc"] = {pose_data_enc.x, pose_data_enc.y, pose_data_enc.z};
    out["position_htc"] = {pose_data_htc.x, pose_data_htc.y, pose_data_htc.z};
    out["position_realsense"] = {pose_data_realsense.x, pose_data_realsense.y,pose_data_realsense.z};
    out["position_imu"] = {pose_data_imu.x*0, pose_data_imu.y*0, pose_data_imu.z};
    out["position_ekf"] = {pose_data_ekf.x, pose_data_ekf.y, pose_data_ekf.z};
    out["attitude_ekf"] = pose_data_ekf.theta;


    // 6. PRINT FOR DEBUG 
    if (PRINT_OUTPUT) {
      cout << "\n\n___________ Computed Pose Data: ____________\n\n";
      cout << "Encoder-based Pose: x = " << pose_data_enc.x
           << ", y = " << pose_data_enc.y << ", z = " << pose_data_enc.z
           << ", theta = " << pose_data_enc.theta
           << ", timecode = " << pose_data_enc.timecode << endl;
      cout << "HTC Pose: x = " << pose_data_htc.x << ", y = " << pose_data_htc.y
           << ", z = " << pose_data_htc.z << ", theta = " << pose_data_htc.theta
           << ", timecode = " << pose_data_htc.timecode << endl;
      cout << "Realsense Pose: x = " << pose_data_realsense.x
           << ", y = " << pose_data_realsense.y
           << ", z = " << pose_data_realsense.z
           << ", theta = " << pose_data_realsense.theta
           << ", timecode = " << pose_data_realsense.timecode << endl;
      cout << "IMU Pose: x = " << pose_data_imu.x << ", y = " << pose_data_imu.y
           << ", z = " << pose_data_imu.z << ", theta = " << pose_data_imu.theta
           << ", timecode = " << pose_data_imu.timecode << endl;
    }
    return return_type::success;
  }


  void compute_mse(double htc_x, double htc_y, double ekf_x, double ekf_y) {
    // 1. Calcolo l'errore quadratico per questo istante
    double err_x = htc_x - ekf_x;
    double err_y = htc_y - ekf_y;
    double sq_error = (err_x * err_x) + (err_y * err_y);

    // 2. Accumulo
    sum_sq_error += sq_error;
    sample_count++;

    // 3. Calcolo la media (MSE)
    current_mse = sum_sq_error / sample_count;

    // 4. Stampa (opzionale: potresti volerlo stampare ogni N cicli per non intasare il terminale)
    if (sample_count % 100 == 0) {
        std::cout << "[MSE] Current Mean Square Error: " << current_mse << " m^2" << std::endl;
        // Se vuoi la distanza media in metri, stampa la radice quadrata (RMSE)
        std::cout << "[RMSE] Root Mean Square Error: " << std::sqrt(current_mse) << " m" << std::endl;
    }
  }


  void set_params(void const *params) override {
    Filter::set_params(params);
    _params.merge_patch(*(json *)params);

    // 1.A. PHYSICAL PARAMETERS
    R_L = _params["R_L"];
    R_R = _params["R_R"];
    n0 = _params["n0"];
    b = _params["b"];

    // 1.B. SENSOR OFFSETS (from calibration)
    a_x_off_imu = _params["a_x_off_imu"];
    a_y_off_imu = _params["a_y_off_imu"];
    w_z_off_imu = _params["w_z_off_imu"];

    // 1:C. EKF TUNING PARAMETERS
    double q_p = _params["q_pos"];     // process noise for position
    double q_y = _params["q_yaw"];     // process noise for yaw
    double r_i = _params["r_imu_yaw"]; // measurement noise for IMU yaw
    double r_rp =
        _params["r_rs_pos"]; // measurement noise for Realsense position
    double r_ry = _params["r_rs_yaw"]; // measurement noise for Realsense yaw

    // 2. EKF INITIALIZATION
    ekf_ptr = std::make_unique<ExtendedKalmanFilter>(R_L, R_R, b, n0);
    if (ekf_first_init) {
      ekf_ptr->init(0.0, 0.0, 0.0, encoder_data.timecode); // Partiamo da 0
      ekf_first_init = false;
    }

    // 3. EKF TUNING (da calibrare empiricamente)
    ekf_ptr->set_tuning(q_p, q_y, r_i, r_rp, r_ry);
  }

  // Implement this method if you want to provide additional information
  map<string, string> info() override {
    // return a map of strings with additional information about the plugin
    // it is used to print the information about the plugin when it is loaded
    // by the agent
    return {};
  };

private:
  // kinematic parameters
  double R_L; // raggio ruota sinistra [m]
  double R_R; // raggio ruota destra [m]
  int n0;     // tics per giro
  double b;   // distanza tra ruote [m]

  // ENCODER
  EncoderData encoder_data;
  PoseData pose_data_enc;
  double last_time_enc = 0.0;
  int last_enc_L = 0;
  int last_enc_R = 0;
  bool ekf_first_init = true;

  // REALSENSE
  RealsenseData realsense_data;
  PoseData pose_data_realsense;
  double last_time_rs = 0.0;

  // IMU
  IMUData imu_data;
  PoseData pose_data_imu;
  double last_time_imu = 0.0;
  double x_dot_IMU = 0.0;
  double y_dot_IMU = 0.0;
  double a_x_off_imu, a_y_off_imu, w_z_off_imu;

  // HTC
  HTCData htc_data;
  PoseData pose_data_htc;

  // EKF
  std::unique_ptr<ExtendedKalmanFilter> ekf_ptr;
  PoseData pose_data_ekf;


  // MSE
  double sum_sq_error = 0.0;
  long sample_count = 0;
  double current_mse = 0.0;
};

/*
____ _ _ _ _
| _ \| |_ _ __ _(_)_ __ __| |_ __(_)_ _____ _ __
| |_) | | | | |/ _` | | '_ \ / _` | '__| \ \ / / _ \ '__|
| __/| | |_| | (_| | | | | | | (_| | | | |\ V / __/ |
|_| |_|\__,_|\__, |_|_| |_| \__,_|_| |_| \_/ \___|_|
|___/
Enable the class as plugin
*/
INSTALL_FILTER_DRIVER(Pose_estimationPlugin, json, json);

/*
_
_ __ ___ __ _(_)_ __
| '_ ` _ \ / _` | | '_ \
| | | | | | (_| | | | | |
|_| |_| |_|\__,_|_|_| |_|
*/

int main(int argc, char const *argv[]) {
  Pose_estimationPlugin plugin;
  json params;
  json input, output;

  // Set example values to params
  params["test"] = "value";

  // Set the parameters
  plugin.set_params(&params);

  // Set input data
  input["data"] = {{"AX", 1}, {"AY", 2}, {"AZ", 3}};

  // Set input data
  plugin.load_data(input);
  cout << "Input: " << input.dump(2) << endl;

  // Process data
  plugin.process(output);
  cout << "Output: " << output.dump(2) << endl;

  return 0;
}
